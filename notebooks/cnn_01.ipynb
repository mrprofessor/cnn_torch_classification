{
 "cells": [
  {
   "cell_type": "code",
   "id": "87680ea3308b6e32",
   "metadata": {},
   "source": [
    "import torch\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights, vgg19, VGG19_Weights\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c975c7d2f9a5ac68",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "image_width = 150\n",
    "image_height = 150\n",
    "epochs_size = 15\n",
    "batch_size = 64\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.0001\n",
    "gamma = 0.055\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(150 , 150)) ,\n",
    "    transforms.ColorJitter(0.4,0.5,0.5,0.2),\n",
    "    transforms.RandomHorizontalFlip(p=0.5) , \n",
    "    transforms.RandomCrop(size=(150,150)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))\n",
    "])\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.425, 0.415, 0.405), (0.255, 0.245, 0.235))\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)), \n",
    "    transforms.ToTensor()\n",
    "]) \n",
    "\n",
    "print(f\"Epochs: {epochs_size}, \" +\n",
    "        f\"Batch Size: {batch_size}, \" +\n",
    "        f\"Learning Rate: {learning_rate}, \" +\n",
    "        f\"Dropout Rate: {dropout_rate}, \" +\n",
    "        f\"Gamma: {gamma}\")\n",
    "\n",
    "\n",
    "print(f\"Epochs: {epochs_size}, Batch Size: {batch_size}, Learning Rate: {learning_rate}, Dropout Rate: {dropout_rate}\")\n",
    "\n",
    "# Classes\n",
    "classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "class_size = len(classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check whether Nvidia GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():  # Multi-Process Service\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"{device} device is available\")"
   ],
   "id": "aee8f72a0bb9b855",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de6088c7b6120fb",
   "metadata": {},
   "source": [
    "# Paths\n",
    "train_path = '../input/intel-image-classification/seg_train/seg_train/'\n",
    "test_path = '../input/intel-image-classification/seg_test/seg_test/'\n",
    "\n",
    "# Load data\n",
    "train_data = ImageFolder(train_path, transform=transform)\n",
    "test_data = ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# Split data\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_data, val_data = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = wide_resnet50_2(weights=Wide_ResNet50_2_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.required_grad = False\n",
    "    \n",
    "number_feature = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=number_feature , out_features=len(classes))\n",
    "cnn_summary = summary(model, input_size=(1, 3, image_width, image_height))\n",
    "print(cnn_summary)\n",
    "# Pytorch summary seems to change the device of the model\n",
    "model = model.to(device)"
   ],
   "id": "bab497917cc10936",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b615c5acc5355ed",
   "metadata": {},
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self, class_size, dropout_rate):\n",
    "        super(CNN1, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=128 * 17 * 17, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=class_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 128 * 17 * 17)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN1(class_size=6, dropout_rate=dropout_rate).to(device)\n",
    "cnn_summary = summary(model, input_size=(1, 3, image_width, image_height))\n",
    "print(cnn_summary)\n",
    "# Pytorch summary seems to change the device of the model\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = vgg19(weights=VGG19_Weights.IMAGENET1K_V1)\n",
    "for param in model.parameters():\n",
    "    param.required_grad = False\n",
    "\n",
    "\n",
    "cnn_summary = summary(model, input_size=(1, 3, image_width, image_height))\n",
    "print(cnn_summary)\n",
    "# Pytorch summary seems to change the device of the model\n",
    "model = model.to(device)"
   ],
   "id": "d271f889d4a6a605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self, class_size, dropout_rate):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        # size = 150x150x32\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        # size = 75x75x64\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        # size = 37x37x128\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        # size = 18x18x256\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        # size = 9x9x512\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # size = 4x4x512\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(in_features=512 * 4 * 4, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=class_size)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(256)\n",
    "        self.batch_norm5 = nn.BatchNorm2d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.batch_norm1(self.conv1(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.batch_norm2(self.conv2(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.batch_norm3(self.conv3(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.batch_norm4(self.conv4(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.batch_norm5(self.conv5(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 512 * 4 * 4)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = ImprovedCNN(class_size=6, dropout_rate=dropout_rate).to(device)\n",
    "cnn_summary = summary(model, input_size=(1, 3, image_width, image_height))\n",
    "print(cnn_summary)\n",
    "# Pytorch summary seems to change the device of the model\n",
    "model = model.to(device)\n"
   ],
   "id": "46b3b3d6ca52a94d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f869b213ad60619a",
   "metadata": {},
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "schedule_learning = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer , milestones=[3 , 6 ] ,\n",
    "                                                        gamma=gamma)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "train_count = len(glob.glob(train_path + '/**/*.jpg'))\n",
    "test_count = len(glob.glob(test_path + '/**/*.jpg'))\n",
    "print(train_count, test_count)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e36d00eb5a2a9fb8",
   "metadata": {},
   "source": [
    "# Train and validate the model\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "for epoch in range(epochs_size):\n",
    "    model.train()\n",
    "    train_loss_current = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_current += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss.append(train_loss_current / len(train_loader))\n",
    "    train_accuracy.append(100 * correct_train / total_train)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss_current = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss_current += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss.append(val_loss_current / len(val_loader))\n",
    "    val_accuracy.append(100 * correct_val / total_val)\n",
    "    \n",
    "    schedule_learning.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs_size} => \"\n",
    "          f\"Train Loss: {train_loss[-1]:.4f}, Train Accuracy: {train_accuracy[-1]:.2f}%, \"\n",
    "          f\"Validation Loss: {val_loss[-1]:.4f}, Validation Accuracy: {val_accuracy[-1]:.2f}%\")\n",
    "\n",
    "# print val_loss and train_loss\n",
    "print(f\"train_loss = {train_loss}\")\n",
    "print(f\"val_loss = {val_loss}\")\n",
    "print(f\"train_accuracy = {train_accuracy}\")\n",
    "print(f\"val_accuracy = {val_accuracy}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f4967a6aed4cb88d",
   "metadata": {},
   "source": [
    "# Plot training and validation loss and accuracy horizontally\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae741a455c10106",
   "metadata": {},
   "source": [
    "# Finally Test the model\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "print(f\"Test Accuracy: {100 * correct_test / total_test:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify the worst classified example of each of the six classes. \"Worst\" is defined as having the max difference between probability of predicted but wrong class and probability of correct class. \n",
    "model.eval()\n",
    "worst_classified = {\n",
    "    'buildings': { 'difference': 0.0, 'image': None},\n",
    "    'forest': {'difference': 0.0, 'image': None},\n",
    "    'glacier': { 'difference': 0.0, 'image': None},\n",
    "    'mountain': {'difference': 0.0, 'image': None},\n",
    "    'sea': {'difference': 0.0, 'image': None},\n",
    "    'street': {'difference': 0.0, 'image': None},\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        img = inputs[i].view(1,3,150,150)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(len(predicted)):\n",
    "            if predicted[j] != labels[j]:\n",
    "                difference = outputs[j][predicted[j]] - outputs[j][labels[j]]\n",
    "                if difference > worst_classified[classes[labels[j]]]['difference']:\n",
    "                    worst_classified[classes[labels[j]]]['difference'] = difference\n",
    "                    worst_classified[classes[labels[j]]]['image'] = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "\n",
    "\n",
    "    \n",
    "# plot all the images horizontally and show both actual and predicted classes\n",
    "\n",
    "# getting error in this code\n",
    "# Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
    "plt.figure(figsize=(20, 30))\n",
    "i = 0\n",
    "for key, value in worst_classified.items():\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.title(f\"Predicted: {key}, Actual: {classes[(classes.index(key) + 1) % 6]}, Difference: {value['difference']:.4f}\")\n",
    "    plt.axis('off')\n",
    "    plt.imshow(value['image'])\n",
    "    i = i + 1"
   ],
   "id": "5003d3a0199d14b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a2f5f1cec50430bc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
